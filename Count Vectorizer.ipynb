{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is commonly used in methods of document classification where the frequency/count of each word is used as a feature for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two text documents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"I love my cat but the cat sat on my face\"\n",
    "text2 = \"I love my dog but the dog sat on my bed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = text1.split(\" \")\n",
    "words2 = text2.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'my', 'cat', 'but', 'the', 'cat', 'sat', 'on', 'my', 'face']\n"
     ]
    }
   ],
   "source": [
    "print(words1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the Words into a Single Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog', 'but', 'love', 'face', 'I', 'my', 'bed', 'cat', 'sat', 'the', 'on'}\n"
     ]
    }
   ],
   "source": [
    "corpus = set(words1).union(set(words2))\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_8916e474_08d9_11e9_9353_106530649311\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >I love my cat but the cat sat on my face</th> \n",
       "        <th class=\"col_heading level0 col1\" >I love my dog but the dog sat on my bed</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row0\" class=\"row_heading level0 row0\" >bed</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row0_col0\" class=\"data row0 col0\" >0</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row0_col1\" class=\"data row0 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row1\" class=\"row_heading level0 row1\" >but</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row1_col0\" class=\"data row1 col0\" >1</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row1_col1\" class=\"data row1 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row2\" class=\"row_heading level0 row2\" >cat</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row2_col0\" class=\"data row2 col0\" >2</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row2_col1\" class=\"data row2 col1\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row3\" class=\"row_heading level0 row3\" >dog</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row3_col0\" class=\"data row3 col0\" >0</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row3_col1\" class=\"data row3 col1\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row4\" class=\"row_heading level0 row4\" >face</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row4_col0\" class=\"data row4 col0\" >1</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row4_col1\" class=\"data row4 col1\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row5\" class=\"row_heading level0 row5\" >love</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row5_col0\" class=\"data row5 col0\" >1</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row5_col1\" class=\"data row5 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row6\" class=\"row_heading level0 row6\" >my</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row6_col0\" class=\"data row6 col0\" >2</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row6_col1\" class=\"data row6 col1\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row7\" class=\"row_heading level0 row7\" >on</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row7_col0\" class=\"data row7 col0\" >1</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row7_col1\" class=\"data row7 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row8\" class=\"row_heading level0 row8\" >sat</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row8_col0\" class=\"data row8 col0\" >1</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row8_col1\" class=\"data row8 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8916e474_08d9_11e9_9353_106530649311level0_row9\" class=\"row_heading level0 row9\" >the</th> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row9_col0\" class=\"data row9 col0\" >1</td> \n",
       "        <td id=\"T_8916e474_08d9_11e9_9353_106530649311row9_col1\" class=\"data row9 col1\" >1</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d79d13fb70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    \"I love my cat but the cat sat on my face\",\n",
    "    \"I love my dog but the dog sat on my bed\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in corpus]\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X.T.todense(), index = feature_names, columns = corpus_index)\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of all the words as features are exported to a dataframe which can be utilized for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
